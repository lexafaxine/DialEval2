{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d32bca-7cc3-4834-b695-10b56d24cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib2 import Path\n",
    "import preprocess\n",
    "from data_loader import create_dataset, create_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab63070-3bd4-4761-8dfa-d22302bb15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_dir, language):\n",
    "    if language == \"Chinese\":\n",
    "        train_path = data_dir / \"train_cn.json\"\n",
    "        test_path = data_dir / \"test_cn.json\"\n",
    "        dev_path = data_dir / \"dev_cn.json\"\n",
    "\n",
    "    elif language == \"English\":\n",
    "        train_path = data_dir / \"train_en.json\"\n",
    "        test_path = data_dir / \"test_en.json\"\n",
    "        dev_path = data_dir / \"dev_en.json\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Language must be English or Chinese\")\n",
    "\n",
    "    if not os.path.isfile(test_path):\n",
    "        test_path = None\n",
    "\n",
    "    return train_path, dev_path, test_path\n",
    "\n",
    "data_dir = \"./dataset\"\n",
    "language = \"Chinese\"\n",
    "train_path, dev_path, test_path = prepare_data(data_dir=Path(data_dir), language=language)\n",
    "train_path, dev_path, test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a7dce-3e95-4ea1-8312-7c93498fca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input, customer_labels, helpdesk_labels, _, embedding_size  = create_inputs(json_path=train_path, plm=\"BERT\",\n",
    "                                                max_len=512,\n",
    "                                                is_train=True, language=\"Chinese\")\n",
    "inputs = (model_input, customer_labels, helpdesk_labels, [])\n",
    "dataset, max_turn_number = create_dataset(inputs, \"nugget\", 10000)\n",
    "a = list(dataset.take(1))\n",
    "input_ids = a[0][\"input_ids\"]\n",
    "input_mask = a[0][\"input_mask\"]\n",
    "input_type_ids = a[0][\"input_type_ids\"]\n",
    "sentence_ids = a[0][\"sentence_ids\"]\n",
    "sentence_masks = a[0][\"sentence_masks\"]\n",
    "inputs = {\n",
    "        \"input_ids\": input_ids, \"input_mask\": input_mask, \"input_type_ids\": input_type_ids,\n",
    "        \"sentence_ids\": sentence_ids, \"sentence_masks\": sentence_masks\n",
    "    }\n",
    "from model import Bert\n",
    "plm = Bert(language=language, embedding_size=embedding_size)\n",
    "\n",
    "x = plm(inputs)\n",
    "\n",
    "from model import TransformerEncoder\n",
    "encoder = TransformerEncoder(d_model=768, num_heads=8, d_ff=200, maximum_position_encoding=10000, rate=0.1, num_layers=2)\n",
    "posemb = encoder.pos_encoding[:, :7, :]\n",
    "x += posemb\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "sentence_masks = create_padding_mask(sentence_masks)\n",
    "\n",
    "for i in range(encoder.num_layers):\n",
    "    x = encoder.enc_layers[i](x, training=True, mask=sentence_masks)\n",
    "    \n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e96252d-5ccd-406c-b47d-cf080f9c0333",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2=x\n",
    "customer_indices = tf.range(start=0, delta=2, limit=max_turn_number)\n",
    "helpdesk_indices = tf.range(start=1, delta=2, limit=max_turn_number)\n",
    "sentence_masks = a[0][\"sentence_masks\"]\n",
    "cres = tf.gather(res2, indices=customer_indices, axis=1)\n",
    "hres = tf.gather(res2, indices=helpdesk_indices, axis=1)\n",
    "\n",
    "cust_mask = tf.gather(sentence_masks, axis=1, indices=customer_indices)\n",
    "\n",
    "customer_dense = tf.keras.layers.Dense(5, activation='gelu')\n",
    "clogits = customer_dense(cres) * tf.cast(cust_mask[:, :, None], tf.float32)\n",
    "\n",
    "cprob = tf.nn.softmax(clogits)\n",
    "clabels = a[0][\"customer_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d613e4-a5b6-45f6-a1e1-a47c4fafcf58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cprob.shape, clabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215fe53f-e411-4e6c-9fd8-c0fb0180ce6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "squared_difference = tf.math.squared_difference(\n",
    "    cprob, clabels, name=None\n",
    ")\n",
    "squared_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be2a32c-68b0-48db-adb2-dfff8d25791e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "squared_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6764fe42-6780-477c-b55c-5a9f326c525a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mid = tf.reduce_sum(squared_difference, axis=-1)\n",
    "mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4924c200-d991-4a21-941a-6af01dadbf8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aa = -tf.experimental.numpy.log2(tf.math.sqrt(mid / 2))\n",
    "aa   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b27e26a-7bb1-4d11-99a1-bbc55720ce56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xx = aa * tf.cast(cust_mask, tf.float32)\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a9a7e4-6430-4e97-af40-09d9a76ddba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = tf.math.count_nonzero(xx, axis=-1)\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c7fdf-f8c8-402b-9b1e-483613c8b34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.divide(tf.reduce_sum(xx, axis=-1), tf.cast(bb,dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3eccf1-6fbc-41ac-a7c8-5122f7900e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_mean(tf.math.divide(tf.reduce_sum(xx, axis=-1), tf.cast(bb,dtype=tf.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed63073-f248-4d16-b7bc-7e30544806f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0bf8d5-1081-4f72-b70a-9c112a035565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.reduce_mean(aa, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2899c1-7563-4f39-951c-3e62fa45650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_mean(xx, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c7346-eb4b-4321-8d4c-b62d0380d7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = tf.reduce_sum(mid, axis=-1)\n",
    "from math import log2\n",
    "-log2(tf.reduce_mean(tf.math.sqrt(r/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2508519-aa03-4c62-a7bc-596f56ed3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_rnss = tf.math.sqrt(tf.reduce_sum(tf.reduce_sum(squared_difference, axis=-1), axis=-1) / 2)\n",
    "-tf.experimental.numpy.log2(cus_rnss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8751ac6c-389b-4b4c-9f1b-d22e50456dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def squared_error(pred, truth):\n",
    "    return ((pred - truth) ** 2)\n",
    "\n",
    "cprob_numpy = cprob.numpy()\n",
    "ctruth_numpy = clabels.numpy()\n",
    "squared_error(cprob_numpy, ctruth_numpy) * cust_mask[:, :, None].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0199b0-1dc9-4d3f-a34e-0e8d61c76c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
