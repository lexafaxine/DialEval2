{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf30a412-85a6-4888-a820-0e768fcb4378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 15:41:06.580545: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-08 15:41:06.580581: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib2 import Path\n",
    "import preprocess\n",
    "from data_loader import create_dataset, create_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a6f224e-c1a8-4deb-b4f2-2b21f64a7e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('dataset/train_cn.json'), PosixPath('dataset/dev_cn.json'), None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_data(data_dir, language):\n",
    "    if language == \"Chinese\":\n",
    "        train_path = data_dir / \"train_cn.json\"\n",
    "        test_path = data_dir / \"test_cn.json\"\n",
    "        dev_path = data_dir / \"dev_cn.json\"\n",
    "\n",
    "    elif language == \"English\":\n",
    "        train_path = data_dir / \"train_en.json\"\n",
    "        test_path = data_dir / \"test_en.json\"\n",
    "        dev_path = data_dir / \"dev_en.json\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Language must be English or Chinese\")\n",
    "\n",
    "    if not os.path.isfile(test_path):\n",
    "        test_path = None\n",
    "\n",
    "    return train_path, dev_path, test_path\n",
    "\n",
    "data_dir = \"./dataset\"\n",
    "language = \"Chinese\"\n",
    "train_path, dev_path, test_path = prepare_data(data_dir=Path(data_dir), language=language)\n",
    "train_path, dev_path, test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f6bf887-dbed-422e-95cf-3c11e81d3b15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 15:41:07.668935: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-08 15:41:07.668973: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-08 15:41:07.668987: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-EFG9I9T): /proc/driver/nvidia/version does not exist\n",
      "2021-12-08 15:41:07.669186: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(str(train_path), \"BERT\", 256, \"train\", \"Chinese\", \"nugget\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "299062e8-3dd8-4628-9d62-94ea77d3c877",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': <tf.Tensor: shape=(16, 256), dtype=int32, numpy=\n",
       "  array([[ 101, 6380, 7607, ...,    0,    0,    0],\n",
       "         [ 101,  137,  704, ...,    0,    0,    0],\n",
       "         [ 101,  137,  704, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101,  137,  704, ...,    0,    0,    0],\n",
       "         [ 101,  137, 3180, ...,    0,    0,    0],\n",
       "         [ 101, 7237, 2094, ...,    0,    0,    0]], dtype=int32)>,\n",
       "  'input_mask': <tf.Tensor: shape=(16, 256), dtype=int32, numpy=\n",
       "  array([[1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>,\n",
       "  'input_type_ids': <tf.Tensor: shape=(16, 256), dtype=int32, numpy=\n",
       "  array([[0, 0, 0, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>,\n",
       "  'sentence_ids': <tf.Tensor: shape=(16, 7), dtype=int32, numpy=\n",
       "  array([[  0,  41,  79,  96, 110,   0,   0],\n",
       "         [  0,  63,   0,   0,   0,   0,   0],\n",
       "         [  0,  43,  81,  83,  85, 117,   0],\n",
       "         [  0,  51, 102, 131, 182,   0,   0],\n",
       "         [  0, 144,   0,   0,   0,   0,   0],\n",
       "         [  0,  70, 126,   0,   0,   0,   0],\n",
       "         [  0, 139,   0,   0,   0,   0,   0],\n",
       "         [  0,  67, 121, 144, 170, 205,   0],\n",
       "         [  0,  39,  58, 116,   0,   0,   0],\n",
       "         [  0,  42,  84, 126, 168, 210,   0],\n",
       "         [  0,  57,  70,   0,   0,   0,   0],\n",
       "         [  0,  64, 128, 192,   0,   0,   0],\n",
       "         [  0,  58,   0,   0,   0,   0,   0],\n",
       "         [  0, 122,   0,   0,   0,   0,   0],\n",
       "         [  0, 108,   0,   0,   0,   0,   0],\n",
       "         [  0, 132, 150, 163, 185, 191,   0]], dtype=int32)>,\n",
       "  'sentence_masks': <tf.Tensor: shape=(16, 7), dtype=int32, numpy=\n",
       "  array([[1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0]], dtype=int32)>,\n",
       "  'customer_labels': <tf.Tensor: shape=(16, 4, 4), dtype=float32, numpy=\n",
       "  array([[[0.84210527, 0.10526316, 0.        , 0.05263158],\n",
       "          [0.10526316, 0.68421054, 0.        , 0.21052632],\n",
       "          [0.21052632, 0.42105263, 0.        , 0.36842105],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ]],\n",
       "  \n",
       "         [[0.84210527, 0.        , 0.        , 0.15789473],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ]],\n",
       "  \n",
       "         [[0.8947368 , 0.        , 0.        , 0.10526316],\n",
       "          [0.        , 0.15789473, 0.        , 0.84210527],\n",
       "          [0.        , 0.15789473, 0.6315789 , 0.21052632],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ]],\n",
       "  \n",
       "         [[0.5263158 , 0.        , 0.        , 0.47368422],\n",
       "          [0.        , 0.5263158 , 0.        , 0.47368422],\n",
       "          [0.        , 0.42105263, 0.        , 0.57894737],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ]],\n",
       "  \n",
       "         [[0.84210527, 0.        , 0.        , 0.15789473],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ]],\n",
       "  \n",
       "         [[0.8947368 , 0.05263158, 0.        , 0.05263158],\n",
       "          [0.        , 0.31578946, 0.6315789 , 0.05263158],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ]],\n",
       "  \n",
       "         [[0.8947368 , 0.        , 0.        , 0.10526316],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ]],\n",
       "  \n",
       "         [[0.94736844, 0.        , 0.        , 0.05263158],\n",
       "          [0.05263158, 0.68421054, 0.        , 0.2631579 ],\n",
       "          [0.        , 0.47368422, 0.        , 0.5263158 ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ]],\n",
       "  \n",
       "         [[0.84210527, 0.        , 0.        , 0.15789473],\n",
       "          [0.        , 0.68421054, 0.05263158, 0.2631579 ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ]],\n",
       "  \n",
       "         [[0.94736844, 0.        , 0.        , 0.05263158],\n",
       "          [0.10526316, 0.7368421 , 0.        , 0.15789473],\n",
       "          [0.        , 0.84210527, 0.        , 0.15789473],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ]],\n",
       "  \n",
       "         [[0.7894737 , 0.        , 0.        , 0.21052632],\n",
       "          [0.        , 0.47368422, 0.05263158, 0.47368422],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ]],\n",
       "  \n",
       "         [[0.94736844, 0.        , 0.        , 0.05263158],\n",
       "          [0.        , 0.6315789 , 0.        , 0.36842105],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ]],\n",
       "  \n",
       "         [[0.94736844, 0.        , 0.        , 0.05263158],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ]],\n",
       "  \n",
       "         [[0.84210527, 0.        , 0.        , 0.15789473],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ]],\n",
       "  \n",
       "         [[0.7368421 , 0.        , 0.        , 0.2631579 ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ]],\n",
       "  \n",
       "         [[0.8947368 , 0.        , 0.        , 0.10526316],\n",
       "          [0.        , 0.84210527, 0.        , 0.15789473],\n",
       "          [0.        , 0.7894737 , 0.        , 0.21052632],\n",
       "          [0.25      , 0.25      , 0.25      , 0.25      ]]], dtype=float32)>,\n",
       "  'helpdesk_labels': <tf.Tensor: shape=(16, 3, 3), dtype=float32, numpy=\n",
       "  array([[[0.7368421 , 0.21052632, 0.05263158],\n",
       "          [0.6315789 , 0.10526316, 0.2631579 ],\n",
       "          [0.33333334, 0.33333334, 0.33333334]],\n",
       "  \n",
       "         [[0.47368422, 0.15789473, 0.36842105],\n",
       "          [0.33333334, 0.33333334, 0.33333334],\n",
       "          [0.33333334, 0.33333334, 0.33333334]],\n",
       "  \n",
       "         [[0.42105263, 0.47368422, 0.10526316],\n",
       "          [0.15789473, 0.        , 0.84210527],\n",
       "          [0.21052632, 0.10526316, 0.68421054]],\n",
       "  \n",
       "         [[0.57894737, 0.        , 0.42105263],\n",
       "          [0.47368422, 0.10526316, 0.42105263],\n",
       "          [0.33333334, 0.33333334, 0.33333334]],\n",
       "  \n",
       "         [[0.5263158 , 0.21052632, 0.2631579 ],\n",
       "          [0.33333334, 0.33333334, 0.33333334],\n",
       "          [0.33333334, 0.33333334, 0.33333334]],\n",
       "  \n",
       "         [[0.6315789 , 0.2631579 , 0.10526316],\n",
       "          [0.33333334, 0.33333334, 0.33333334],\n",
       "          [0.33333334, 0.33333334, 0.33333334]],\n",
       "  \n",
       "         [[0.68421054, 0.15789473, 0.15789473],\n",
       "          [0.33333334, 0.33333334, 0.33333334],\n",
       "          [0.33333334, 0.33333334, 0.33333334]],\n",
       "  \n",
       "         [[0.6315789 , 0.2631579 , 0.10526316],\n",
       "          [0.6315789 , 0.2631579 , 0.10526316],\n",
       "          [0.42105263, 0.05263158, 0.5263158 ]],\n",
       "  \n",
       "         [[0.7368421 , 0.        , 0.2631579 ],\n",
       "          [0.68421054, 0.        , 0.31578946],\n",
       "          [0.33333334, 0.33333334, 0.33333334]],\n",
       "  \n",
       "         [[0.7368421 , 0.21052632, 0.05263158],\n",
       "          [0.68421054, 0.15789473, 0.15789473],\n",
       "          [0.57894737, 0.10526316, 0.31578946]],\n",
       "  \n",
       "         [[0.5263158 , 0.21052632, 0.2631579 ],\n",
       "          [0.33333334, 0.33333334, 0.33333334],\n",
       "          [0.33333334, 0.33333334, 0.33333334]],\n",
       "  \n",
       "         [[0.57894737, 0.21052632, 0.21052632],\n",
       "          [0.5263158 , 0.10526316, 0.36842105],\n",
       "          [0.33333334, 0.33333334, 0.33333334]],\n",
       "  \n",
       "         [[0.31578946, 0.57894737, 0.10526316],\n",
       "          [0.33333334, 0.33333334, 0.33333334],\n",
       "          [0.33333334, 0.33333334, 0.33333334]],\n",
       "  \n",
       "         [[0.6315789 , 0.10526316, 0.2631579 ],\n",
       "          [0.33333334, 0.33333334, 0.33333334],\n",
       "          [0.33333334, 0.33333334, 0.33333334]],\n",
       "  \n",
       "         [[0.42105263, 0.31578946, 0.2631579 ],\n",
       "          [0.33333334, 0.33333334, 0.33333334],\n",
       "          [0.33333334, 0.33333334, 0.33333334]],\n",
       "  \n",
       "         [[0.84210527, 0.        , 0.15789473],\n",
       "          [0.7894737 , 0.        , 0.21052632],\n",
       "          [0.7368421 , 0.        , 0.2631579 ]]], dtype=float32)>}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(dataset.take(1))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c82394b-de73-4543-be7d-8f00fe615389",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.count_nonzero(a[0][\"sentence_masks\"][0], axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5973ea88-77e0-4297-8a48-438fa5e642d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = create_dataset(data, \"nugget\")\n",
    "a = list(dataset.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d761ae-8e5c-4407-83ba-80379cb2645a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2046f0c2-03d9-48e1-8341-e088dd30f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def gen(n):\n",
    "    for i in range(n):\n",
    "        yield i, 2*i + 1\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def get_dataset():\n",
    "    dataset = tf.data.Dataset.from_generator(partial(gen, 10),\n",
    "                                            output_types=(tf.int32, tf.int32))\n",
    "    dataset = dataset.batch(3).repeat()\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6febf872-cf41-47c9-af42-86340d20e32b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = get_dataset()\n",
    "a = list(dataset.take(100))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10403e1-8c6d-4ceb-bc7c-8dcdc20650f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = list(dataset2.take(1))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1df795-db70-4f80-885e-279e66409652",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83201c63-e9f9-4a7b-bc6d-4b4ff6606158",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in dataset2.as_numpy_iterator():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d38a86-3626-4db9-9658-bf0c7247ab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in dataset2.as_numpy_iterator():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b243a6d-9949-4a49-b6ae-ca5cb734c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = list(dataset.take(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060468a7-15b6-4539-9354-cb17c664ad7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff461a-f151-424f-b93c-b69d24d5f674",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(dataset.take(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc02323-28dc-4009-a659-60d404b71f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973cc2fd-e119-4213-b802-aa7f97da9cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
