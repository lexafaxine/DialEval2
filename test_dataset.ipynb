{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf30a412-85a6-4888-a820-0e768fcb4378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 14:06:17.305322: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-11 14:06:17.305352: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib2 import Path\n",
    "import preprocess\n",
    "from data_loader import create_dataset, create_inputs, create_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a6f224e-c1a8-4deb-b4f2-2b21f64a7e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('dataset/train_cn.json'), PosixPath('dataset/dev_cn.json'), None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_data(data_dir, language):\n",
    "    if language == \"Chinese\":\n",
    "        train_path = data_dir / \"train_cn.json\"\n",
    "        test_path = data_dir / \"test_cn.json\"\n",
    "        dev_path = data_dir / \"dev_cn.json\"\n",
    "\n",
    "    elif language == \"English\":\n",
    "        train_path = data_dir / \"train_en.json\"\n",
    "        test_path = data_dir / \"test_en.json\"\n",
    "        dev_path = data_dir / \"dev_en.json\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Language must be English or Chinese\")\n",
    "\n",
    "    if not os.path.isfile(test_path):\n",
    "        test_path = None\n",
    "\n",
    "    return train_path, dev_path, test_path\n",
    "\n",
    "data_dir = \"./dataset\"\n",
    "language = \"Chinese\"\n",
    "train_path, dev_path, test_path = prepare_data(data_dir=Path(data_dir), language=language)\n",
    "train_path, dev_path, test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bee8dd0-10cd-47ac-a843-29540b36996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor, embedding_size = create_processor(plm=\"BERT\", max_len=256, language=\"Chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3389a39-dd8d-45e5-818a-4ee397e53810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.05263158 0.6315789  0.21052632 0.10526316]\n",
      " [0.         0.15789473 0.57894737 0.05263158 0.21052632]\n",
      " [0.         0.         0.7368421  0.         0.2631579 ]]\n"
     ]
    }
   ],
   "source": [
    "raw_data = json.load(open(train_path))\n",
    "for dialogue in raw_data:\n",
    "    example = processor.process_dialogue(dialogue, mode=\"train\", task=\"nugget\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e668ef0-3366-43c4-af36-5002286faa02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.2, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.2, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.2, 0.2, 0.2, 0.2, 0.2]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[1/5] * 5] * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6bf887-dbed-422e-95cf-3c11e81d3b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = create_dataset(str(train_path), \"BERT\", 256, \"train\", \"Chinese\", \"nugget\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299062e8-3dd8-4628-9d62-94ea77d3c877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = list(dataset.take(1))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c82394b-de73-4543-be7d-8f00fe615389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.math.count_nonzero(a[0][\"sentence_masks\"][0], axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5973ea88-77e0-4297-8a48-438fa5e642d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = create_dataset(data, \"nugget\")\n",
    "a = list(dataset.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d761ae-8e5c-4407-83ba-80379cb2645a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2046f0c2-03d9-48e1-8341-e088dd30f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def gen(n):\n",
    "    for i in range(n):\n",
    "        yield i, 2*i + 1\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def get_dataset():\n",
    "    dataset = tf.data.Dataset.from_generator(partial(gen, 10),\n",
    "                                            output_types=(tf.int32, tf.int32))\n",
    "    dataset = dataset.batch(3).repeat()\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6febf872-cf41-47c9-af42-86340d20e32b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = get_dataset()\n",
    "a = list(dataset.take(100))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10403e1-8c6d-4ceb-bc7c-8dcdc20650f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = list(dataset2.take(1))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1df795-db70-4f80-885e-279e66409652",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83201c63-e9f9-4a7b-bc6d-4b4ff6606158",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in dataset2.as_numpy_iterator():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d38a86-3626-4db9-9658-bf0c7247ab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in dataset2.as_numpy_iterator():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b243a6d-9949-4a49-b6ae-ca5cb734c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = list(dataset.take(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060468a7-15b6-4539-9354-cb17c664ad7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff461a-f151-424f-b93c-b69d24d5f674",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(dataset.take(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc02323-28dc-4009-a659-60d404b71f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973cc2fd-e119-4213-b802-aa7f97da9cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
